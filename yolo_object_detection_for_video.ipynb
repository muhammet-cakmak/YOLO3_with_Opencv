{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Object Detection with YOLO and OpenCV\n",
    "\n",
    "YOLO is a deep learning algorithm and a state-of-the-art real time object detection algorithm which came out in May 2016. It is so popular because it is so fast compared with the other deep learning object detection models.\n",
    "\n",
    "In traditional methods we use windows to calculate scores within a image. We use the highest score to say there is an object. YOLO uses different methods. It uses bounding boxes (anchors) to determine the objects in the image with the help of neural network. It uses probabilities of the boxes. It is assumed that a box with highest score detects the object. Neural network sees image just once. That'S why YOLO algorims is called \"You only look once algorithm\".\n",
    "\n",
    "![Screenshot%202020-07-20%20at%2019.09.43.png](attachment:Screenshot%202020-07-20%20at%2019.09.43.png)\n",
    "Resource:(https://pjreddie.com/media/files/papers/YOLOv3.pdf)\n",
    "\n",
    "It can be seen from above picture that YOLO3 is at least 3 times faster than the others.\n",
    "\n",
    "YOLO3 accepts three different input forms as Image file, webcam feed and video file.\n",
    "\n",
    "We will use pre-trained YOLOv3 algorithm and it's weights. It is capable of detecting 80 different objects such as person, bicycle and car.\n",
    "\n",
    "For transfer learning we need to:\n",
    "* download weight file of YOLO\n",
    "* download configuration file of YOLO\n",
    "* download name file - coco\n",
    "* install OpenCV 3.4.2 or above\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**---------------------------------------------------------**\n",
    "* download config file: https://github.com/pjreddie/darknet/tree/master/cfg\n",
    "* download weights: https://pjreddie.com/darknet/yolo/\n",
    "* download coco.names:https://github.com/pjreddie/darknet/blob/master/data/coco.names\n",
    "* !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# we are loading yolo weights, configuration and object names.\n",
    "# Open cv nin bu fonksiyonu weights leri yüklemek ve configürasyonu yapmak için yazılmıştır. Bu bize model objesi \n",
    "# dönecek ve bunu daha sonra predictions yapmak için kullanacağız.\n",
    "net = cv2.dnn.readNet('/Users/muhammet/Desktop/yolo3_nesne_tanima/yolov3.weights', '/Users/muhammet/Desktop/yolo3_nesne_tanima/yolov3.cfg')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# coco.names den object names leri extract edelim ve bunları classes diye bir listeye alalım\n",
    "\n",
    "classes = []\n",
    "with open('/Users/muhammet/Desktop/yolo3_nesne_tanima/coco.names', 'r') as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "# Şimdi kendi seçtiğimiz bir foto üzerinden gidelim. \n",
    "# Bu fotounun size ını 416x416 boyutuna indirgeyip, 255' e bölerek scale edeceğiz.\n",
    "\n",
    "\n",
    "\n",
    "# video kullanmak için. \n",
    "# WEBCAM için cap= cv2.VideoCapture(0)  yapmamız yeterli.\n",
    "\n",
    "cap= cv2.VideoCapture('/Users/muhammet/Desktop/yolo3_nesne_tanima/street_video.mp4')  # videoyu folderdan okur.\n",
    "\n",
    "\n",
    "while True:\n",
    "    # videonun her bir frameini okuyacağız yani fotolardan oluştuğu için her bir sahnesi bir fotodur aslında\n",
    "    \n",
    "    _, img = cap.read()\n",
    "    \n",
    "    \n",
    "    height, width, _ = img.shape    # fotonun boyutlarını tutar. _ burada fotonun renk sayısını tutar ve 3 tür.\n",
    "\n",
    "\n",
    "    # swapRB=True BGR olan renk sırasını RGB ye cevirir.\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416,416), (0,0,0), swapRB=True, crop=False)\n",
    "\n",
    "\n",
    "    # bu fotoyu düzenledikten sonra modele input olarak veriyotuz\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # tahmin değerleri  , boxes dimensions ya da tahmin sınıfları gibi bilgileri almak için output layer ın ismini alıp\n",
    "    # forward functiona bu ismi girdi vermeliyiz.\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layer_outputs = net.forward(output_layers_names)\n",
    "    \n",
    "\n",
    "    # Burada bütün hesaplamalar yapıldı ve layer_outputs içinde bütün boxes ve prediction değerleri var.\n",
    "    # Şimdi bunları ayıralım\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Boxes \n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    # buradaki detectionın ilk 4 değeri box boyutunu, 5. değeri nesne olasılığını ve diğerleri 80 sınıf olasılığını verir.\n",
    "    # yani toplamda 85 değeri tutuyor.\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:] # sınıfların olasılıklarını tutar.\n",
    "            class_id = np.argmax(scores) # en yüksek skorun locasyonunu tutar\n",
    "            confidence = scores[class_id] # en yüksek olasılık değerini alır.\n",
    "            # burada confidence ı alıyoruz çünkü bunu bir eşikle kabul edip etmeyeceğimize karar vereceğiz.\n",
    "            threshold = 0.5\n",
    "            if confidence > threshold:\n",
    "            # x ve y boxes ın x ve y eksenin tam orta nokasıdır.width nesnenin genişliği(x ekseni), height boyu (y ekseni)\n",
    "            # Bunları yukarıda girdi verdiğimiz resim boyutları ile çarparız ve kutunun resimdeki gerçek yerini buluruz.\n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)         # width\n",
    "                h = int(detection[3]*height)         # height\n",
    "\n",
    "\n",
    "                # box ın sol üst köşesini belirleyelim\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "\n",
    "                boxes.append([x,y,w,h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "        # Bütün gerekli bilgileri almış olduk.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # bir objeyi birden fazla boxes işaretlemiş olabilir. Bu durumda non-maximum suppressions kullanılır ve\n",
    "    # en yüksek olasılıklı olan alınır\n",
    "    # 0.4 non-max suppresiion degeridir.\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, threshold, 0.4)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_PLAIN    # kutuların üzerindeki yazıların fontunu belirler.\n",
    "    colors = np.random.uniform(0,255, size = (len(boxes),3))   # kutuların renklerini belirler\n",
    "\n",
    "    if len(indexes)>0:\n",
    "        for i in indexes.flatten():\n",
    "            x,y,w,h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i],2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) # box ın boyutunu ve obje üzerindeki yerini veriyoruz.\n",
    "            cv2.putText(img, label + \" \"+ confidence, (x, y+20), font, 1.2, (255,255,255), 2) # obje üstündeki texti verir.\n",
    "\n",
    "\n",
    "\n",
    "        # fotoyu görmek istersek\n",
    "\n",
    "        cv2.imshow('Image', img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
