{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Object Detection with YOLO and OpenCV\n",
    "\n",
    "YOLO is a deep learning algorithm and a state-of-the-art real time object detection algorithm which came out in May 2016. It is so popular because it is so fast compared with the other deep learning object detection models.\n",
    "\n",
    "In traditional methods we use windows to calculate scores within a image. We use the highest score to say there is an object. YOLO uses different methods. It uses bounding boxes (anchors) to determine the objects in the image with the help of neural network. It uses probabilities of the boxes. It is assumed that a box with highest score detects the object. Neural network sees image just once. That'S why YOLO algorims is called \"You only look once algorithm\".\n",
    "\n",
    "\n",
    "Resource:(https://pjreddie.com/media/files/papers/YOLOv3.pdf)\n",
    "\n",
    "It can be seen from above picture that YOLO3 is at least 3 times faster than the others.\n",
    "\n",
    "YOLO3 accepts three different input forms as Image file, webcam feed and video file.\n",
    "\n",
    "We will use pre-trained YOLOv3 algorithm and it's weights. It is capable of detecting 80 different objects such as person, bicycle and car.\n",
    "\n",
    "For transfer learning we need to:\n",
    "* download weight file of YOLO\n",
    "* download configuration file of YOLO\n",
    "* download name file - coco\n",
    "* install OpenCV 3.4.2 or above\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**---------------------------------------------------------**\n",
    "* download config file: https://github.com/pjreddie/darknet/tree/master/cfg\n",
    "* download weights: https://pjreddie.com/darknet/yolo/\n",
    "* download coco.names:https://github.com/pjreddie/darknet/blob/master/data/coco.names\n",
    "* !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# we are loading yolo weights, configuration and object names.\n",
    "\n",
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract the object names from \"coco.names\" and put them in a list called \"classes\".\n",
    "\n",
    "classes = []\n",
    "with open('coco.names', 'r') as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for WEBCAM  write  \"cap= cv2.VideoCapture(0)\" .\n",
    "\n",
    "cap= cv2.VideoCapture('street_video.mp4')  \n",
    "\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    _, img = cap.read()\n",
    "    \n",
    "    \n",
    "    height, width, _ = img.shape     # keeps the shape of the image\n",
    "\n",
    "\n",
    "   # Here we convert the image to blob. So we are converting the image to numpy.ndarray FORMAT\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416,416), (0,0,0), swapRB=True, crop=False)\n",
    "\n",
    "\n",
    "   # After editing this photo, we set it to the model as input.\n",
    "    net.setInput(blob)\n",
    "\n",
    "    \n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layer_outputs = net.forward(output_layers_names)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Boxes \n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    #  where the first 4 values of detection give the box sizes, the 5th value is the object probability, and the others are the 80 classes' probabilities.\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:] \n",
    "            class_id = np.argmax(scores) \n",
    "            confidence = scores[class_id] \n",
    "            \n",
    "            # theshold of probability\n",
    "            threshold = 0.5\n",
    "            if confidence > threshold:\n",
    "            \n",
    "            \n",
    "        \n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)         # width\n",
    "                h = int(detection[3]*height)         # height\n",
    "\n",
    "\n",
    "                # Let's determine the upper left corner of the box\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "\n",
    "                boxes.append([x,y,w,h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  An object may have more than one box marked. In this case, non-maximum suppressions are used and the most likely to be taken\n",
    "# 0.4 is non-max suppression value.\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, threshold, 0.4)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_PLAIN    # determines the font of the text on the boxes.\n",
    "    colors = np.random.uniform(0,255, size = (len(boxes),3))  # determines the color of the boxes\n",
    "\n",
    "    if len(indexes)>0:\n",
    "        for i in indexes.flatten():\n",
    "            x,y,w,h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i],2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2) \n",
    "            cv2.putText(img, label + \" \"+ confidence, (x, y+20), font, 1.2, (255,255,255), 2) \n",
    "\n",
    "\n",
    "\n",
    "        # To show the image and object determination on the image\n",
    "\n",
    "        cv2.imshow('Image', img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
